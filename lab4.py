# -*- coding: utf-8 -*-
"""lab4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18XrG6Q8b10nddf9AVhVJCMjDe_blBnzj
"""

from keras.layers import Dense, Flatten
from keras.models import Sequential
from keras.datasets import mnist
from keras.utils import to_categorical
from keras import optimizers
from PIL import Image
import numpy
import matplotlib.pyplot as plt
from keras.optimizers import SGD
from keras.optimizers import  RMSprop
from keras.optimizers import  Adam

def loadImg(path):
    return numpy.asarray(Image.open(path))


(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

train_images = train_images / 255.0
test_images = test_images / 255.0

model = Sequential()
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(10, activation='softmax'))


def getModel(optimizer, name):
    model.compile(optimizer=name, loss='categorical_crossentropy', metrics=['accuracy'])
    h = model.fit(train_images, train_labels, epochs=5, verbose=0, batch_size=128, validation_data=(test_images, test_labels))

    print((h.history['accuracy']), h.history['val_accuracy'])
    plt.figure(1, figsize=(8, 5))
    plt.title('Training and test accuracy ' + name)
    plt.plot(h.history['accuracy'], 'r', label='train')
    plt.plot(h.history['val_accuracy'], 'b', label='test')
    plt.legend()
    plt.show()
    plt.clf()

    plt.figure(1, figsize=(8, 5))
    plt.title('Training and test loss ' + name)
    plt.plot(h.history['loss'], 'r', label='train')
    plt.plot(h.history['val_loss'], 'b', label='test')
    plt.legend()
    plt.show()
    plt.clf()

opt = Adam(learning_rate=0.05)
getModel(opt, 'Adam')